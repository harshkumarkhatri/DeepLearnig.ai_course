{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnmdKnGNnjDo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "d43e5392-9844-4bb2-cc0a-bd98625ab17f"
      },
      "source": [
        "import tensorflow as tf\n",
        "mnist=tf.keras.datasets.fashion_mnist\n",
        "(training_images,training_labels),(test_images,test_labels)=mnist.load_data()\n",
        "training_images=training_images/255.0\n",
        "\n",
        "test_images=test_images/255.0\n",
        "model=tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512,activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10,activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile('adam','sparse_categorical_crossentropy',['accuracy'])\n",
        "model.fit(training_images,training_labels,epochs=5)\n",
        "test_loss=model.evaluate(test_images,test_labels)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4743 - accuracy: 0.8309\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3595 - accuracy: 0.8689\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3198 - accuracy: 0.8812\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2984 - accuracy: 0.8881\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2810 - accuracy: 0.8958\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3410 - accuracy: 0.8777\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zomDPgBxrZVV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "0283bdf9-5591-4a49-f983-7c02361ccf5b"
      },
      "source": [
        "import tensorflow as tf\n",
        "mnist=tf.keras.datasets.fashion_mnist\n",
        "(training_images,training_labels),(test_images,test_labels)=mnist.load_data()\n",
        "training_images=training_images.reshape(60000, 28, 28, 1)\n",
        "training_images=training_images / 255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images=test_images/255.0\n",
        "model=tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(64,(3,3),activation='relu',input_shape=(28,28,1)),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512,activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10,activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile('adam','sparse_categorical_crossentropy',['accuracy'])\n",
        "model.fit(training_images,training_labels,epochs=5)\n",
        "test_loss=model.evaluate(test_images,test_labels)\n",
        "\n",
        "# 64 is the number of convolutional we would like to generate\n",
        "# (3,3) is the grid size which we want. The output image has certain less data becaues the boundary pixels are removed as they do not have neighbours.\n",
        "# Through maxPooling we will be reducng the size of the image.\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.5762 - accuracy: 0.7850\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.3751 - accuracy: 0.8609\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.3221 - accuracy: 0.8803\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2868 - accuracy: 0.8928\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2616 - accuracy: 0.9024\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3199 - accuracy: 0.8873\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}